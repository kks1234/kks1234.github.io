<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>00Hadoop集群搭建之模板系统</title>
      <link href="/posts/3732411068.html"/>
      <url>/posts/3732411068.html</url>
      
        <content type="html"><![CDATA[<h2 id="Hadoop集群搭建之模板系统"><a href="#Hadoop集群搭建之模板系统" class="headerlink" title="Hadoop集群搭建之模板系统"></a>Hadoop集群搭建之模板系统</h2><h4 id="模板虚拟机环境准备"><a href="#模板虚拟机环境准备" class="headerlink" title="模板虚拟机环境准备"></a>模板虚拟机环境准备</h4><ul><li>安装模板虚拟机，IP 地址 192.168.88.100、 主机名称 hadoop100、内存 6G、 硬盘 100G(根据自己的机器情况配置)</li><li>hadoop100 虚拟机配置要求如下（本文 Linux 系统全部以 CentOS-7-x86_64-DVD-2009.iso 为例 ）  （清华镜像地址：<a href="https://mirrors.tuna.tsinghua.edu.cn/centos/7.9.2009/isos/x86_64/%EF%BC%89">https://mirrors.tuna.tsinghua.edu.cn/centos/7.9.2009/isos/x86_64/）</a></li></ul><h4 id="VMware虚拟机安装"><a href="#VMware虚拟机安装" class="headerlink" title="VMware虚拟机安装"></a>VMware虚拟机安装</h4><p>本人在服务器操作VMware为英文版</p><ol><li>点击创建一个虚拟机</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307804.png" alt="image-20211123013640626"></p><ol start="2"><li>选择高级安装，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307014.png" alt="image-20211123013821232"></p><ol start="3"><li>以下显示的是版本兼容性，直接点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307597.png" alt="image-20211123013925731"></p><ol start="4"><li>下一步选择稍后安装系统，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307304.png" alt="image-20211123014042409"></p><ol start="5"><li>选择Linux系统，cnetos7 64 位，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307701.png" alt="image-20211123014131595"></p><ol start="6"><li>设置虚拟机名字，设置为Hadoop100，存储位置设置为自己想保存的文件夹，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307135.png" alt="image-20211123014307516"></p><ol start="7"><li>设置虚拟机CPU配置，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307845.png" alt="image-20211123014433291"></p><ol start="8"><li>设置虚拟机内存，由于内存较多所以设置6G，内存不足可以设置为2G-4G，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307413.png" alt="image-20211123014629673"></p><ol start="9"><li>选择网络连接模式，在这里配置为net模式(模式具体区别可自行百度)，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307693.png" alt="image-20211123014741403"></p><ol start="10"><li>选择默认推荐模式，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307510.png" alt="image-20211123014856520"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072307421.png" alt="image-20211123014907147"></p><ol start="11"><li>选择新建虚拟磁盘，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308709.png" alt="image-20211123014919700"></p><ol start="12"><li>修改创建磁盘大小，最好50G以上，该模式不会直接占用50G，而是代表最大占用50G，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308613.png" alt="image-20211123015229906"></p><ol start="13"><li>将虚拟机保存至刚才的目录，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308213.png" alt="image-20211123015418804"></p><ol start="14"><li>点击结束，配置完成。</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308511.png" alt="image-20211123015506875"></p><ol start="15"><li>右键虚拟机点击设置</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308430.png" alt="image-20211123015654068"></p><ol start="16"><li>选择CD&#x2F;DVD，选择使用镜像文件，选择在清华镜像站下载的镜像，点击save</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308654.png" alt="image-20211123015730028"></p><ol start="17"><li>开启虚拟机</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308254.png" alt="image-20211123015928485"></p><p>18.选择安装CentOS 7，等待加载</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308492.png" alt="image-20211123020000039"></p><ol start="19"><li>使用中文简体，点击继续</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308214.png" alt="image-20211123020139561"></p><ol start="20"><li>点击日期选择上海，点击完成</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308070.png" alt="image-20211123020259703"></p><ol start="21"><li>点击软件选择，选择桌面安装，并选择一些开发工具包，点击完成</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308397.png" alt="image-20211123020417453"></p><ol start="22"><li>点击安装位置，我要分区，点击完成</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072339861.png" alt="image-20211123020511882"></p><ol start="23"><li>挂在三个分区，如图，点击完成</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072338618.png" alt="image-20211123020649529"></p><ol start="24"><li>点击开始安装，并自己设置用户和root密码，等待系统安装完成。</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072308318.png" alt="image-20211123020800984"></p><ol start="25"><li>安装完成，点击重启</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309742.png" alt="image-20211123021927056"></p><ol start="26"><li>点击接受，完成配置</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309021.png" alt="image-20211123022050803"></p><p>27.登录用户，可选择未列出登录root用户</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309137.png" alt="image-20211123022134211"></p><p>28.进入系统</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309126.png" alt="image-20211123022244570"></p><p>29.配置虚拟机ip</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072311275.png" alt="image-20211123022639267"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309510.png" alt="image-20211123023039103"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072311374.png" alt="image-20211123023218069"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309997.png" alt="image-20211123023249919"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072311197.png" alt="image-20211123023522286"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309655.png" alt="image-20211126223938752"></p><ol start="30"><li>配置vmware网络设置</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309624.png" alt="image-20211123023824712"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309438.png" alt="image-20211123023912937"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309245.png" alt="image-20211123024009183"></p><ol start="31"><li>重启虚拟机，测试虚拟机</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309558.png" alt="image-20211123024342725"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309630.png" alt="image-20211123024353259"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072309327.png" alt="image-20211123024405624"></p><ol start="32"><li><p>安装epel-release  </p><p>注： Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、 CentOS 和 Scientific Linux。相当于是一个软件仓库， 大多数 rpm 包在官方repository 中是找不到的）</p></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br></pre></td></tr></table></figure><ol start="33"><li>关闭防护墙并防止开机自启</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure><p>​注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙  </p><ol start="34"><li>在&#x2F;opt 目录下创建文件夹  module、software 一般软件安装放在opt目录中。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/module /opt/software</span><br></pre></td></tr></table></figure><ol start="35"><li>删除自带的java SDK</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure><p><img src="/pic/image-20211123025204418.png" alt="image-20211123025204418"></p><p>自此模板虚拟机安装完成。</p><p>百度网盘资料包</p><p>链接：<a href="https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ">https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ</a><br>提取码：0xgs</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>01虚拟机克隆和软件安装</title>
      <link href="/posts/1329881792.html"/>
      <url>/posts/1329881792.html</url>
      
        <content type="html"><![CDATA[<h2 id="虚拟机克隆和软件安装"><a href="#虚拟机克隆和软件安装" class="headerlink" title="虚拟机克隆和软件安装"></a>虚拟机克隆和软件安装</h2><h4 id="虚拟机克隆"><a href="#虚拟机克隆" class="headerlink" title="虚拟机克隆"></a>虚拟机克隆</h4><ol><li>在电脑创建三个文件夹用来保存虚拟机文件。</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312597.png" alt="image-20211123234429664"></p><ol start="2"><li>右键上节的模板虚拟机，管理，克隆虚拟机</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312598.png" alt="image-20211123234553984"></p><ol start="3"><li>点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312599.png" alt="image-20211123234632944"></p><ol start="4"><li>默认选项，点击next</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312600.png" alt="image-20211123234647745"></p><p>5.选择完整克隆，点击next</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312601.png" alt="image-20211123234706120"></p><p>6.名字命名为hadoop101，位置选择创建的文件夹地址，点击next</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312602.png" alt="image-20211123234738076"></p><p>7.点击finsh，等待克隆完成，不同电脑等待时间不同。</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312603.png" alt="image-20211123234745867"></p><ol start="8"><li>以此再创建两台虚拟机，hadoop102、hadoop103，一共三台虚拟机。</li></ol><p>修改每个虚拟机的hostname、和IP地址，并重启。</p><p>hadoop101 192.168.88.101<br>hadoop102 192.168.88.102<br>hadoop103 192.168.88.103</p><ol start="9"><li>验证各个虚拟机的ip和hostname</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312605.png" alt="image-20211124000419027"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312606.png" alt="image-20211124000503787"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312607.png" alt="image-20211124000534372"></p><h4 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h4><ol><li>将资源包里的文件传入虚拟机的&#x2F;opt&#x2F;software目录下</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312608.png" alt="image-20211125124413057"></p><ol start="2"><li>将两个压缩文件解压至&#x2F;opt&#x2F;module下</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-8u212-linux-x64.tar.gz  -C /opt/module/</span><br><span class="line">tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312609.png" alt="image-20211125125116357"></p><ol start="3"><li>下面配置环境变量</li></ol><p>创建文件 vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh 文件  添加如下的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312610.png" alt="image-20211125125410620"></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>更新环境变量</p><ol start="4"><li>测试环境，配置成功</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072312611.png" alt="image-20211125125642121"></p><p>百度网盘资料包</p><p>链接：<a href="https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ">https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ</a><br>提取码：0xgs</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>02Hadoop目录和运行模式</title>
      <link href="/posts/3101278308.html"/>
      <url>/posts/3101278308.html</url>
      
        <content type="html"><![CDATA[<h2 id="Hadoop目录和运行模式"><a href="#Hadoop目录和运行模式" class="headerlink" title="Hadoop目录和运行模式"></a>Hadoop目录和运行模式</h2><h3 id="Hadoop目录结构："><a href="#Hadoop目录结构：" class="headerlink" title="Hadoop目录结构："></a>Hadoop目录结构：</h3><p><img src="http://qiniu.kks1234.xyz/imgs/202206080019762.png" alt="image-20220608001907027"></p><h3 id="Hadoop重要目录："><a href="#Hadoop重要目录：" class="headerlink" title="Hadoop重要目录："></a>Hadoop重要目录：</h3><p>（1）bin 目录：存放对 Hadoop 相关服务（hdfs，yarn，mapred）进行操作的脚本 </p><p>（2）etc 目录：Hadoop 的配置文件目录，存放 Hadoop 的配置文件 </p><p>（3）lib 目录：存放 Hadoop 的本地库（对数据进行压缩解压缩功能）</p><p>（4）sbin 目录：存放启动或停止 Hadoop 相关服务的脚本 </p><p>（5）share 目录：存放 Hadoop 的依赖 jar 包、文档、和官方案例</p><h3 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h3><p>Hadoop 运行模式包括：<strong>本地模式</strong>、<strong>伪分布式模式</strong>以及<strong>完全分布式模式</strong>。</p><ul><li>本地模式：单机运行，只是用来演示一下官方案例。生产环境不用。</li><li>伪分布式模式：也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模 拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。</li><li>完全分布式模式：多台服务器组成分布式环境。生产环境使用。</li></ul><p>我们已经在hadoop101这台虚拟机中安装了hadoop和java，我们可以在虚拟机中对其进行单机测试</p><ol><li>首先创建一个文本文件如下：</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206080026090.png" alt="image-20220608001438704"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206080026220.png" alt="image-20220608001416392"></p><ol start="2"><li>然后我们运行hadoop自带的一个字符个数统计的demo</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoopmapreduce-examples-3.1.3.jar wordcount 1.txt  ./output </span><br></pre></td></tr></table></figure><ol start="3"><li>在output文件夹中查看程序的运行结果：</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206080043300.png" alt="image-20220608004313690"></p><ol start="4"><li>单机模式测试完成，但实际中我们需要的是完全分布式模式。</li></ol><p>完全分布式运行模式是开发的重点，也是我们主要学习的模式，下篇配置三台hadoop集群</p><p>我们现在的准备以及后续的准备有：</p><p>1）准备 3 台客户机（关闭防火墙、静态 IP、主机名称）<strong>√</strong> </p><p>2）安装 JDK <strong>√</strong> （Hadoop101）</p><p>3）配置系统环境变量 <strong>√</strong> （Hadoop101）</p><p>4）安装 Hadoop <strong>√</strong> （Hadoop101）</p><p>5）配置 ssh 和分发脚本</p><p>6）配置Hadoop环境变量 </p><p>7）配置集群</p><p>8）启动并测试集群</p><p>百度网盘资料包</p><p>链接：<a href="https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ">https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ</a><br>提取码：0xgs</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>03Hadoop集群搭建配置</title>
      <link href="/posts/3798968528.html"/>
      <url>/posts/3798968528.html</url>
      
        <content type="html"><![CDATA[<h2 id="Hadoop集群搭建配置"><a href="#Hadoop集群搭建配置" class="headerlink" title="Hadoop集群搭建配置"></a>Hadoop集群搭建配置</h2><h3 id="至今为止我们做好的准备："><a href="#至今为止我们做好的准备：" class="headerlink" title="至今为止我们做好的准备："></a>至今为止我们做好的准备：</h3><p>1）准备 3 台客户机（关闭防火墙、静态 IP、主机名称）<strong>√</strong> </p><p>2）安装 JDK <strong>√</strong> （Hadoop101）</p><p>3）配置系统环境变量 <strong>√</strong> （Hadoop101）</p><p>4）安装 Hadoop <strong>√</strong> （Hadoop101）</p><p>5）配置 ssh 和分发脚本</p><p>6）配置Hadoop环境变量 </p><p>7）配置集群</p><p>8）启动并测试集群</p><h3 id="SSH无密钥登陆的配置"><a href="#SSH无密钥登陆的配置" class="headerlink" title="SSH无密钥登陆的配置"></a>SSH无密钥登陆的配置</h3><p>​首先，为什么需要配置虚拟机之间的无密钥登录，这是因为我们对设置文件的配置，要在各个节点之间统一，所以要频繁进行通信，ssh无密钥登录为配置文件分发脚本服务。</p><p>​无密钥的原理是加密中的非对称加密，node1连接node2，需要node1生成公钥和密钥对，然后node1将公钥传输给node2，这样在node1用ssh连接node2时，node2将一段验证文用公钥加密，然后传输给node1，而node1用私钥对其进行解密，传输给node2，node2收到解密后的验证后和自己发送的验证进行对比，如果一样这样就<strong>唯一确定</strong>了node1的身份，就可以直接连接。</p><ol><li>生成公钥和私钥</li></ol><p>进入</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313807.png" alt="image-20211126215532200"></p><p>目录，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>三次回车，</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313808.png" alt="image-20211126215638216"></p><p>生成两个文件 id_rsa（私钥）、id_rsa.pub（公钥）</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313809.png" alt="image-20211126215724845"></p><ol start="2"><li>将公钥拷贝到要免密登录的目标机器上</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id  [user@]hadoop101</span><br><span class="line">ssh-copy-id  [user@]hadoop102</span><br><span class="line">ssh-copy-id  [user@]hadoop103</span><br><span class="line"></span><br><span class="line">ssh -v [user@]hadoop101 #测试</span><br></pre></td></tr></table></figure><ol start="3"><li>在另外两台机器上也同时配置一下ssh无密钥登录。</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313810.png" alt="image-20211126224617693"></p><h3 id="编写集群分发脚本-xsync"><a href="#编写集群分发脚本-xsync" class="headerlink" title="编写集群分发脚本 xsync"></a>编写集群分发脚本 xsync</h3><h4 id="SCP"><a href="#SCP" class="headerlink" title="SCP"></a>SCP</h4><ol><li><p>scp（secure copy）安全拷贝可以实现服务器与服务器之间的数据拷贝。</p></li><li><p>基本语法</p></li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313811.png" alt="image-20211126224836783"></p><ol start="3"><li><p>实际操作</p><p>将Hadoop101虚拟机上的&#x2F;opt下的module拷贝到另外两台虚拟机，也就是java和hadoop软件包。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /opt/module/* root@hadoop102:/opt/module</span><br><span class="line">scp -r /opt/module/* root@hadoop103:/opt/module</span><br></pre></td></tr></table></figure></li></ol><h4 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a>rsync 远程同步工具</h4><p>​rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 </p><p>​rsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更 新。scp 是把所有文件都复制过去。</p><ol><li>基本语法</li></ol><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313812.png" alt="image-20211126225546317"></p><h4 id="自己编写xsync-集群分发脚本-尚硅谷"><a href="#自己编写xsync-集群分发脚本-尚硅谷" class="headerlink" title="自己编写xsync 集群分发脚本(尚硅谷)"></a>自己编写xsync 集群分发脚本(尚硅谷)</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/bin/xync</span><br></pre></td></tr></table></figure><p>脚本内容不做解释</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1 arguments count</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">2.foreach files</span></span><br><span class="line">for host in hadoop101 hadoop102 hadoop103</span><br><span class="line">do</span><br><span class="line">    echo ====================  $host  ====================</span><br><span class="line">    #3.foreach dir</span><br><span class="line"></span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        #4. file if exit</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">            then</span><br><span class="line">                #5. get father dir</span><br><span class="line">                pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line"></span><br><span class="line">                #6.get file name</span><br><span class="line">                fname=$(basename $file)</span><br><span class="line">                ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">            else</span><br><span class="line">                echo $file does not exists!</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x xsync</span><br></pre></td></tr></table></figure><p>测试脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /usr/bin</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313813.png" alt="image-20211126230907222"></p><p>同步之前的环境变量配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure><p>在Hadoop102和103上重新加载环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="全分布式配置"><a href="#全分布式配置" class="headerlink" title="全分布式配置"></a>全分布式配置</h3><p>​全部脚本和环境已经准备好，这样我们再三台虚拟机上就都有了java和hadoop环境，都可以单机模式运行，但我们要配置的为全分布式模式，要配置完全分布式模式需要我们对集群的具体hadoop环境部署进行规划，在本例中采用以下的规划方法。</p><table><thead><tr><th></th><th>hadoop101</th><th>hadoop102</th><th>hadoop103</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode、DataNode</td><td>DataNode</td><td>SecondaryNameNode、DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager、NodeManager</td><td>NodeManager</td></tr></tbody></table><h4 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h4><p>​Hadoop 配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。  </p><h5 id="默认配置文件："><a href="#默认配置文件：" class="headerlink" title="默认配置文件："></a>默认配置文件：</h5><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313814.png" alt="image-20211126235555526"></p><p>默认配置文件的内容也可以在官网的文档中获取。</p><h5 id="自定义配置文件-："><a href="#自定义配置文件-：" class="headerlink" title="自定义配置文件 ："></a>自定义配置文件 ：</h5><p>core-site.xml、 hdfs-site.xml、 yarn-site.xml、 mapred-site.xml 四个配置文件存放在$HADOOP_HOME&#x2F;etc&#x2F;hadoop 这个路径上， 用户可以根据项目需求重新进行修改配置。  </p><h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><ol><li><p>配置 core-site.xml  </p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313815.png" alt="image-20211127001548420"></p></li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 NameNode 的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop101:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 HDFS 网页登录使用的静态用户为 root --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>配置 hdfs-site.xml</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web 端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2nn web 端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>配置 yarn-site.xml</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定 MR 走 shuffle<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>指定 ResourceManager 的地址<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO</span><br><span class="line">        NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP</span><br><span class="line">        RED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>环境变量的继承<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>为每个容器请求分配的最小内存限制资源管理器（512M）<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>为每个容器请求分配的最大内存限制资源管理器（4G）<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>虚拟内存比例，默认为2.1，此处设置为4倍<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="4"><li>配置 mapred-site.xml</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>执行MapReduce的方式：yarn/local<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 不配置在报错--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ol start="5"><li><p>配置workers</p><p># 删除第一行localhost，然后添加以下三行</p><p>hadoop101</p><p>hadoop102</p><p>hadoop103</p></li></ol><h4 id="分发配置文件"><a href="#分发配置文件" class="headerlink" title="分发配置文件"></a>分发配置文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.1.3/etc/hadoop/</span><br></pre></td></tr></table></figure><p>查看分发情况，确保配置文件被修改成功。</p><h4 id="发起集群"><a href="#发起集群" class="headerlink" title="发起集群"></a>发起集群</h4><h5 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h5><ol><li>如果集群是第一次启动，需要在 hadoop101 节点格式化 NameNode。<strong>（注意： 格式化 NameNode， 会产生新的集群 id， 导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。 如果集群在运行过程中报错，需要重新格式化 NameNode 的话， 一定要先停止 namenode 和 datanode 进程， 并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。 ）</strong></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format  </span><br></pre></td></tr></table></figure><ol start="2"><li>进入&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3目录，启动 HDFS</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure><p>会发现报错</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313816.png" alt="image-20211127004315649"></p><p>这是因为我们使用的root用户启动，所以把sbin下的start-dfs.sh、stop-dfs.sh添加如下内容。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HDFS_DATANODE_USER=root</span><br><span class="line">HDFS_DATANODE_SECURE_USER=hdfs</span><br><span class="line">HDFS_NAMENODE_USER=root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER=root</span><br></pre></td></tr></table></figure><p>同时也在sbin下的start-yarn.sh、stop-yarn.sh添加如下内容。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">HADOOP_SECURE_DN_USER=yarn</span><br><span class="line">YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure><p>分发脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync ./sbin/</span><br></pre></td></tr></table></figure><p>再次启动dfs，成功。</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313817.png" alt="image-20211127005250202"></p><ol start="3"><li>在<strong>配置了 ResourceManager 的节点</strong>（hadoop102） 启动 YARN</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><p>启动成功。</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313818.png" alt="image-20211127005500284"></p><ol start="4"><li>Web 端查看 HDFS 的 NameNode<br>（a）浏览器中输入： <a href="http://hadoop101:9870/">http://hadoop101:9870</a><br>（b）查看 HDFS 上存储的数据信息</li><li>Web 端查看 YARN 的 ResourceManager<br>   （a）浏览器中输入： <a href="http://hadoop102:8088/">http://hadoop102:8088</a><br>   （b）查看 YARN 上运行的 Job 信息</li></ol><p>查看进行，启动信息符合前面的表格设计。</p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313819.png" alt="image-20211127010103320"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313820.png" alt="image-20211127010123552"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313821.png" alt="image-20211127010203259"></p><h3 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h3><ol><li>普通命令测试</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">上传文件 1.txt是单机测试用例中的字符文本</span></span><br><span class="line">hadoop fs -put 1.txt /</span><br><span class="line">hadoop fs -put /opt/software/hadoop-3.1.3.tar.gz  /</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">统计字数测试</span></span><br><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /1.txt /output</span><br></pre></td></tr></table></figure><ol start="2"><li>启动写入基准测试</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试10个文件，每个文件50M，一共500M</span></span><br><span class="line">hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 50MB</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313822.png" alt="image-20211127014842999"></p><ol start="3"><li>测试读取速度</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">测试10个文件，每个文件50M，一共500M</span></span><br><span class="line">hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 50MB</span><br></pre></td></tr></table></figure><p><img src="http://qiniu.kks1234.xyz/imgs/202206072313823.png" alt="image-20211127015209546"></p><ol start="4"><li>测试期间，会在HDFS集群上创建 &#x2F;benchmarks目录，测试完毕后，我们可以清理该目录。</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -clean</span><br></pre></td></tr></table></figure><p>百度网盘资料包</p><p>链接：<a href="https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ">https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ</a><br>提取码：0xgs</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>04Hadoop功能完善</title>
      <link href="/posts/3480485341.html"/>
      <url>/posts/3480485341.html</url>
      
        <content type="html"><![CDATA[<h2 id="Hadoop功能完善"><a href="#Hadoop功能完善" class="headerlink" title="Hadoop功能完善"></a>Hadoop功能完善</h2><h4 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h4><p>​为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：  </p><p>1） 配置 mapred-site.xml  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure><p>在该文件里面增加如下配置。  </p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 因为yarn安装在Hadoop102机器 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器 web 端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2） 分发配置  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.1.3/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure><p>3） 在 hadoop102 启动历史服务器  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p>4） 查看历史服务器是否启动  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure><p>5） 查看 JobHistory  </p><p><a href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p><h4 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h4><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。  </p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072314514.png" alt="image-20211227221424706"></p><p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。<br>注意：开启日志聚集功能， 需要重新启动 NodeManager 、 ResourceManager 和<br>HistoryServer。  </p><p>1） 配置 yarn-site.xml  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml </span><br></pre></td></tr></table></figure><p>在该文件里面增加如下配置。  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 开启日志聚集功能 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;</span><br><span class="line">&lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 设置日志聚集服务器地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.log.server.url&lt;/name&gt;</span><br><span class="line">&lt;value&gt;http://hadoop102:19888/jobhistory/logs&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;</span><br><span class="line">&lt;value&gt;604800&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>2） 分发配置  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure><p>3） 关闭 NodeManager 、 ResourceManager 和 HistoryServer  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mapred --daemon stop historyserver</span><br><span class="line">sbin/stop-yarn.sh</span><br></pre></td></tr></table></figure><p>4） 启动 NodeManager 、 ResourceManage 和 HistoryServer  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/tart-yarn.sh</span><br><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p>5） 执行 WordCount 程序  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /1.txt /out2</span><br></pre></td></tr></table></figure><p>6） 查看日志  </p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072314515.png" alt="image-20211227230512840"></p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072314516.png" alt="image-20211227230524860"></p><h4 id="集群启动-x2F-停止方式总结"><a href="#集群启动-x2F-停止方式总结" class="headerlink" title="集群启动&#x2F;停止方式总结"></a>集群启动&#x2F;停止方式总结</h4><p>1） 各个模块分开启动&#x2F;停止（配置 ssh 是前提） 常用  </p><p>（1）整体启动&#x2F;停止 HDFS  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh/stop-dfs.sh  </span><br></pre></td></tr></table></figure><p>（2）整体启动&#x2F;停止 YARN  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh/stop-yarn.sh</span><br></pre></td></tr></table></figure><p>2） 各个服务组件逐一启动&#x2F;停止  </p><p>（1）分别启动&#x2F;停止 HDFS 组件  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start/stop namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure><p>（2）启动&#x2F;停止 YARN  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn --daemon start/stop resourcemanager/nodemanager</span><br></pre></td></tr></table></figure><h4 id="编写-Hadoop-集群常用脚本"><a href="#编写-Hadoop-集群常用脚本" class="headerlink" title="编写 Hadoop 集群常用脚本"></a>编写 Hadoop 集群常用脚本</h4><p>1） Hadoop 集群启停脚本（包含 HDFS， Yarn， Historyserver）： myhadoop</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /bin</span><br><span class="line">vim myhadoop</span><br></pre></td></tr></table></figure><p>输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">echo &quot;No Args Input...&quot;</span><br><span class="line">exit ;</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">echo &quot; =================== 启动 hadoop 集群 ===================&quot;</span><br><span class="line">echo &quot; --------------- 启动 hdfs ---------------&quot;</span><br><span class="line">ssh hadoop101 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span><br><span class="line">echo &quot; --------------- 启动 yarn ---------------&quot;</span><br><span class="line">ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span><br><span class="line">echo &quot; --------------- 启动 historyserver ---------------&quot;</span><br><span class="line">ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start</span><br><span class="line">historyserver&quot;</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">echo &quot; =================== 关闭 hadoop 集群 ===================&quot;</span><br><span class="line">echo &quot; --------------- 关闭 historyserver ---------------&quot;</span><br><span class="line">ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop</span><br><span class="line">historyserver&quot;</span><br><span class="line">echo &quot; --------------- 关闭 yarn ---------------&quot;</span><br><span class="line">ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span><br><span class="line">echo &quot; --------------- 关闭 hdfs ---------------&quot;</span><br><span class="line">ssh hadoop101 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">echo &quot;Input Args Error...&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure><p>加权脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x myhadoop</span><br></pre></td></tr></table></figure><p>2）查看三台服务器 Java 进程脚本： jpsall  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /bin</span><br><span class="line">vim jpsall</span><br></pre></td></tr></table></figure><p>输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">for host in hadoop101 hadoop102 hadoop103</span><br><span class="line">do</span><br><span class="line">echo =============== $host ===============</span><br><span class="line">ssh $host jps</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>加权脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x jpsall</span><br></pre></td></tr></table></figure><p>3）分发&#x2F;bin 目录，保证自定义脚本在三台机器上都可以使用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /bin/  </span><br></pre></td></tr></table></figure><h4 id="常用端口号说明"><a href="#常用端口号说明" class="headerlink" title="常用端口号说明"></a>常用端口号说明</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202206072314517.png" alt="image-20211227231520925"></p><h4 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h4><p>​如果服务器在公网环境（能连接外网），可以不采用集群时间同步，因为服务器会定期<br>和公网时间进行校准；<br>​如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，<br>导致集群执行任务时间不同步。  </p><p>1）需求  </p><p>​找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步， 生产环境<br>根据任务对时间的准确程度要求周期同步。 测试环境为了尽快看到效果，采用 1 分钟同步一<br>次。  </p><p><img src="http://qiniu.kks1234.xyz/imgs/202206072314518.png" alt="image-20211227231710477"></p><p>2） 时间服务器配置（必须 root 用户）  </p><p>（1） 查看所有节点 ntpd 服务状态和开机自启动状态  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status ntpd</span><br><span class="line">sudo systemctl start ntpd</span><br><span class="line">sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure><p>（2）修改 hadoop101 的 ntp.conf 配置文件  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ntp.conf  </span><br></pre></td></tr></table></figure><p>（a） 修改 1（授权 192.168.88.0-192.168.88.255 网段上的所有机器可以从这台机器上查<br>询和同步时间） </p><p> <strong>restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</strong></p><p>（b） 修改 2（集群在局域网中，不使用其他互联网上的时间）  注释掉</p><p><strong>#server 0.centos.pool.ntp.org iburst</strong><br><strong>#server 1.centos.pool.ntp.org iburst</strong><br><strong>#server 2.centos.pool.ntp.org iburst</strong><br><strong>#server 3.centos.pool.ntp.org iburst</strong>  </p><p>（c） 添加 3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中<br>的其他节点提供时间同步）  </p><p>（3）修改 hadoop102 的&#x2F;etc&#x2F;sysconfig&#x2F;ntpd 文件  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/sysconfig/ntpd</span><br></pre></td></tr></table></figure><p>增加内容如下（让硬件时间与系统时间一起同步）  </p><p><strong>SYNC_HWCLOCK&#x3D;yes</strong>  </p><p>（4）重新启动 ntpd 服务  、设置 ntpd 服务开机启动  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start ntpd</span><br><span class="line">sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure><p>3） 其他机器配置（必须 root 用户）  </p><p>（1） 关闭所有节点上 ntp 服务和自启动  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop ntpd</span><br><span class="line">sudo systemctl disable ntpd</span><br></pre></td></tr></table></figure><p>（2）在其他机器配置 1 分钟与时间服务器同步一次  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo crontab -e</span><br></pre></td></tr></table></figure><p>编写定时任务如下：  </p><p>***&#x2F;1 * * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate hadoop102**  </p><p>（3）修改任意机器时间  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo date -s &quot;2021-9-11 11:11:11&quot;</span><br></pre></td></tr></table></figure><p>（4） 1 分钟后查看机器是否与时间服务器同步  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo date</span><br></pre></td></tr></table></figure><p>百度网盘资料包</p><p>链接：<a href="https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ">https://pan.baidu.com/s/1fa7sHVFdeS6bzzNeEfmnqQ</a><br>提取码：0xgs</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop概论</title>
      <link href="/posts/2793300014.html"/>
      <url>/posts/2793300014.html</url>
      
        <content type="html"><![CDATA[<h2 id="Hadoop概论"><a href="#Hadoop概论" class="headerlink" title="Hadoop概论"></a>Hadoop概论</h2><h4 id="Hadoop的定义"><a href="#Hadoop的定义" class="headerlink" title="Hadoop的定义"></a>Hadoop的定义</h4><p>​Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个分布式文件系统（ Distributed File System），其中一个组件是HDFS（Hadoop Distributed File System）。HDFS有高容错性的特点，并且设计用来部署在低廉的（low-cost）硬件上；而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。HDFS放宽了（relax）POSIX的要求，可以以流的形式访问（streaming access）文件系统中的数据。Hadoop的框架最核心的设计就是：HDFS和MapReduce。HDFS为海量的数据提供了存储，而MapReduce则为海量的数据提供了计算 。(百度百科)</p><h4 id="Hadoop的诞生"><a href="#Hadoop的诞生" class="headerlink" title="Hadoop的诞生"></a>Hadoop的诞生</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205262308462.png" alt="image-20211123005313228"></p><p>​Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。</p><p>​Apache 版本最原始（最基础）的版本，对于入门学习最好。2006<br>​Cloudera 内部集成了很多大数据框架，对应产品 CDH。2008<br>​Hortonworks 文档较好，对应产品 HDP。2011<br>​Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。 2018<br>​2021宣布所有版本收费</p><h4 id="Hadoop的地位"><a href="#Hadoop的地位" class="headerlink" title="Hadoop的地位"></a>Hadoop的地位</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205262308647.png" alt="image-20211123004608453"></p><center>大数据生态圈</center><p>由此可见，Hadoop位于整个大数据生态圈的最底层，是学习整个大数据框架的关键。</p><h4 id="Hadoop的技术架构"><a href="#Hadoop的技术架构" class="headerlink" title="Hadoop的技术架构"></a>Hadoop的技术架构</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205262308480.png" alt="image-20211123005956862"></p><center>架构图</center><p>现版本为3.x.x，其技术架构和2.0相同。</p><p><img src="http://qiniu.kks1234.xyz/imgs/202205262308799.png" alt="image-20211123011121156"></p><p>主要技术框架：</p><p>​<strong>Hadoop Distributed File System</strong>，简称 <strong>HDFS</strong>，是一个<strong>分布式文件系统</strong>。 用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p><p>​<strong>MapReduce</strong> 是一个<strong>分布式运算程序</strong>的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。</p><p>​<strong>Yarn</strong>是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的<strong>操作系统平台</strong>，而 <strong>MapReduce</strong> 等运算程序则相当于<strong>运行于操作系统之上的应用程序</strong>。</p><h4 id="Hadoop特点"><a href="#Hadoop特点" class="headerlink" title="Hadoop特点"></a>Hadoop特点</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205262308512.png" alt="image-20211123010723684"></p><p>参考链接：<a href="https://blog.csdn.net/qq_42937522/article/details/121016314">https://blog.csdn.net/qq_42937522/article/details/121016314</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据概论</title>
      <link href="/posts/37908005.html"/>
      <url>/posts/37908005.html</url>
      
        <content type="html"><![CDATA[<h2 id="大数据概论"><a href="#大数据概论" class="headerlink" title="大数据概论"></a>大数据概论</h2><h4 id="什么是大数据？"><a href="#什么是大数据？" class="headerlink" title="什么是大数据？"></a>什么是大数据？</h4><p>​大数据(big data)，或称巨量资料，指的是所涉及的资料量规模巨大到无法透过目前主流软件工具，在合理时间内达到撷取、管理、处理、并整理成为帮助企业经营决策更积极目的的资讯。</p><p>​在维克托·迈尔-舍恩伯格维克托·迈尔-舍恩伯格)及肯尼斯·库克耶编写的《大数据时代》 [1] 中大数据指不用随机分析法、抽样调查这样捷径，而采用所有数据进行分析处理。(百度百科)</p><h4 id="大数据的5V特点"><a href="#大数据的5V特点" class="headerlink" title="大数据的5V特点"></a>大数据的5V特点</h4><p>Volume（大量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实性）。</p><p><strong>Volume</strong>：即数据量大</p><p><strong>Velocity</strong>：即数据增长速度快</p><p><strong>Variety</strong>：即种类和来源多样</p><p><strong>Value</strong>：即信息的价值密度低</p><p><strong>Veracity</strong>：即数据可信度高、真实性高</p><h4 id="大数据的应用场景"><a href="#大数据的应用场景" class="headerlink" title="大数据的应用场景"></a>大数据的应用场景</h4><ul><li><p>制造业，利用工业大数据提升制造业水平，包括产品故障诊断与预测、分析工艺流程、改进生产工艺，优化生产过程能耗、工业供应链分析与优化、生产计划与排程。</p></li><li><p>金融行业，大数据在高频交易、社交情绪分析和信贷风险分析三大金融创新领域发挥重大作用。</p></li><li><p>汽车行业，利用大数据和物联网技术的无人驾驶汽车，在不远的未来将走入我们的日常生活。</p></li><li><p>互联网行业，借助于大数据技术，可以分析客户行为，进行商品推荐和针对性广告投放。</p></li><li><p>电信行业，利用大数据技术实现客户离网分析，及时掌握客户离网倾向，出台客户挽留措施。</p></li><li><p>能源行业，随着智能电网的发展，电力公司可以掌握海量的用户用电信息，利用大数据技术分析用户用电模式，可以改进电网运行，合理设计电力需求响应系统，确保电网运行安全。</p></li><li><p>物流行业，利用大数据优化物流网络，提高物流效率，降低物流成本。</p></li><li><p>城市管理，可以利用大数据实现智能交通、环保监测、城市规划和智能安防。</p></li><li><p>生物医学，大数据可以帮助我们实现流行病预测、智慧医疗、健康管理，同时还可以帮助我们解读DNA,了解更多的生命奥秘。</p></li><li><p>体育娱乐，大数据可以帮助我们训练球队，决定投拍哪种题财的影视作品，以及预测比赛结果。</p></li><li><p>安全领域，政府可以利用大数据技术构建起强大的国家安全保障体系，企业可以利用大数据抵御网络攻击，警察可以借助大数据来预防犯罪。</p></li><li><p>个人生活， 大数据还可以应用于个人生活，利用与每个人相关联的“个人大数据”，分析个人生活行为习惯，为其提供更加周到的个性化服务。</p></li></ul><h4 id="大数据分析流程"><a href="#大数据分析流程" class="headerlink" title="大数据分析流程"></a>大数据分析流程</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205250002661.png" alt="image-20211123004105817"></p><h4 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h4><p><img src="http://qiniu.kks1234.xyz/imgs/202205250002285.png" alt="image-20211123011815695"></p><p>1） Sqoop： Sqoop 是一款开源的工具，主要用于在 Hadoop、 Hive 与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL， Oracle 等）中的数据导进到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。<br>2） Flume： Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据；<br>3） Kafka： Kafka 是一种高吞吐量的分布式发布订阅消息系统；  </p><p>4） Spark： Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数据进行计算。<br>5） Flink： Flink 是当前最流行的开源大数据内存计算框架。 用于实时计算的场景较多。<br>6） Oozie： Oozie 是一个管理 Hadoop 作业（job）的工作流程调度管理系统。<br>7）Hbase： HBase 是一个分布式的、面向列的开源数据库。 HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。<br>8） Hive： Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。<br>9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。  </p><p>参考链接：<a href="https://www.jianshu.com/p/1c3e7b416ba7">https://www.jianshu.com/p/1c3e7b416ba7</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
            <tag> 技术 </tag>
            
            <tag> 计算机 </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
